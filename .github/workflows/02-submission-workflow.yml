name: Submission Workflow

on:
  issue_comment:
    types: [created]

permissions:
  contents: write
  pull-requests: write
  issues: write
  pages: write
  id-token: write

jobs:
  triage:
    if: github.event.issue.pull_request
    runs-on: ubuntu-latest
    outputs:
      authorized: ${{ steps.check.outputs.authorized }}
      command: ${{ steps.parse.outputs.command }}
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Check permissions
        id: check
        run: |
          python .github/scripts/check_permissions.py \
            --commenter ${{ github.event.comment.user.login }} \
            --owner ${{ github.repository_owner }} \
            --output authorized.json
          
          authorized=$(cat authorized.json | jq -r '.authorized')
          echo "authorized=$authorized" >> $GITHUB_OUTPUT
          
      - name: Parse command
        id: parse
        run: |
          BODY="${{ github.event.comment.body }}"
          if [[ "$BODY" == *"/test-benchmark"* ]]; then
            echo "command=benchmark" >> $GITHUB_OUTPUT
            echo "Detected benchmark command"
          elif [[ "$BODY" == *"/push-results"* ]]; then
            echo "command=publish" >> $GITHUB_OUTPUT
            echo "Detected publish command"
          else
            echo "command=none" >> $GITHUB_OUTPUT
            echo "No relevant command detected"
          fi

  benchmark:
    needs: triage
    if: needs.triage.outputs.command == 'benchmark' && needs.triage.outputs.authorized == 'true'
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
        with:
          ref: refs/pull/${{ github.event.issue.number }}/head
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install torch --index-url https://download.pytorch.org/whl/cpu

      - name: Run benchmark on CPU
        id: benchmark
        env:
          CUDA_VISIBLE_DEVICES: ""
          HF_ALLOW_CODE_EVAL: "1"
        run: |
          # Use find to properly resolve the wildcard to a single file path
          SUBMISSION_FILE=$(find models/submissions -name "*.yaml" -type f | head -n 1)
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          mkdir -p results/raw
          
          echo "Using submission file: $SUBMISSION_FILE"
          
          python benchmarks/evaluation/run_benchmark.py \
            --submission-file "$SUBMISSION_FILE" \
            --output-dir results/raw/ \
            --save-logs \
            --deterministic \
            --seed 42 \
            --timestamp $TIMESTAMP \
            --limit 5
      
      - name: Process results
        run: |
          python scripts/generate_report.py \
            --results-dir results/raw/ \
            --output results/processed/latest_benchmark.json
      
      - name: Generate visualizations
        run: |
          python scripts/generate_charts.py \
            --results results/processed/latest_benchmark.json \
            --output results/charts/
      
      - name: Comment results summary
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            if (!fs.existsSync('results/processed/latest_benchmark.json')) {
              console.log('Results file not found');
              return;
            }
            const results = JSON.parse(fs.readFileSync('results/processed/latest_benchmark.json', 'utf8'));
            
            let comment = `## ðŸŽ¯ Benchmark Results\n\n`;
            comment += `### Overall Performance\n\n`;
            comment += `| Metric | Score | Rank |\n`;
            comment += `|--------|-------|------|\n`;
            
            if (results.aggregate_scores) {
              Object.entries(results.aggregate_scores).forEach(([metric, data]) => {
                comment += `| ${metric} | ${data.score.toFixed(2)} | #${data.rank} |\n`;
              });
            } else {
              comment += `| N/A | 0.00 | - |\n`;
            }
            
            comment += `\n### Detailed Breakdown\n\n`;
            comment += `<details>\n<summary>Click to expand</summary>\n\n`;
            comment += `\`\`\`json\n${JSON.stringify(results.detailed || {}, null, 2)}\n\`\`\`\n\n`;
            comment += `</details>\n\n`;
            comment += `---\n\n`;
            comment += `âœ… Benchmark completed successfully!\n`;
            comment += `Maintainer can now comment \`/push-results\` to publish to leaderboard.\n`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
      
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: |
            results/raw/
            results/processed/
            results/charts/
          retention-days: 90

  publish:
    needs: triage
    if: needs.triage.outputs.command == 'publish' && needs.triage.outputs.authorized == 'true'
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Download benchmark artifacts
        uses: actions/download-artifact@v4
        with:
          name: benchmark-results
          path: results/
      
      - name: Update registry
        run: |
          # Use find to properly resolve the wildcard
          SUBMISSION_FILE=$(find models/submissions -name "*.yaml" -type f | head -n 1)
          echo "Using submission file: $SUBMISSION_FILE"
          
          python scripts/update_registry.py \
            --submission "$SUBMISSION_FILE" \
            --results results/processed/latest_benchmark.json \
            --registry models/registry.json
      
      - name: Update leaderboard data
        run: |
          python scripts/update_website.py \
            --registry models/registry.json \
            --output website/assets/data/leaderboard.json
      
      - name: Archive results
        run: |
          python scripts/archive_results.py \
            --results results/processed/latest_benchmark.json \
            --archive-dir results/archives/
      
      - name: Commit results
        run: |
          # Use find/xargs safely to get model name
          SUBMISSION_FILE=$(find models/submissions -name "*.yaml" -type f | head -n 1)
          MODEL_NAME=$(grep 'name:' "$SUBMISSION_FILE" | head -1 | cut -d':' -f2 | xargs)
          
          git config user.name "SLM Benchmark Bot"
          git config user.email "bot@slm-benchmark.dev"
          
          git add models/registry.json
          git add results/
          git add website/assets/data/
          
          git commit -m "Add benchmark results for $MODEL_NAME"
          git push origin main
      
      - name: Merge PR
        uses: actions/github-script@v7
        with:
          script: |
            await github.rest.pulls.merge({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number,
              merge_method: 'squash'
            });
      
      - name: Close PR with success comment
        uses: actions/github-script@v7
        with:
          script: |
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: 'ðŸŽ‰ Results published to [leaderboard](https://2796gaurav.github.io/slm-benchmark)!\n\nThank you for your contribution!'
            });
      
      - name: Trigger website deployment
        run: |
          curl -X POST \
            -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            -H "Accept: application/vnd.github.v3+json" \
            https://api.github.com/repos/${{ github.repository }}/dispatches \
            -d '{"event_type":"deploy-website"}'
